{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"E:\\machinelearning\\data\\train.csv\")\n",
    "a,b=np.unique(df[\"target\"],return_counts=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,valid=train_test_split(df,test_size=0.2)\n",
    "train,test=train_test_split(train,test_size=0.01)\n",
    "\n",
    "train[\"image_name_jpg\"]=train[\"image_name\"]+\".jpg\"\n",
    "test[\"image_name_jpg\"]=test[\"image_name\"]+\".jpg\"\n",
    "valid[\"image_name_jpg\"]=valid[\"image_name\"]+\".jpg\"\n",
    "\n",
    "train[\"target\"]=train[\"target\"].astype(str)\n",
    "test[\"target\"]=test[\"target\"].astype(str)\n",
    "valid[\"target\"]=valid[\"target\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26235 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "test_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255) # we have to divide by 255 for testing in android app\n",
    "\n",
    "\n",
    "train_generator =train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=r\"E:/machinelearning/data/train/\",\n",
    "    x_col=\"image_name_jpg\", # name +\".jpg\"\n",
    "    y_col=\"target\",\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6626 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator =test_datagen.flow_from_dataframe(\n",
    "    dataframe=valid,\n",
    "    directory=r\"E:/machinelearning/data/train/\",\n",
    "    x_col=\"image_name_jpg\",\n",
    "    y_col=\"target\",\n",
    "    target_size=(64,64),\n",
    "    batch_size=16,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Building the CNN\n",
    "# Initialising the CNN\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', strides=2, input_shape=[64, 64, 3]))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# Step 5 - Output Layer\n",
    "#cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "## For Binary Classification\n",
    "cnn.add(Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation\n",
    "             ='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 272,545\n",
      "Trainable params: 272,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 820 steps, validate for 415 steps\n",
      "Epoch 1/3\n",
      "820/820 - 55s - loss: 0.0778 - accuracy: 0.8819 - val_loss: 0.0492 - val_accuracy: 0.8814\n",
      "Epoch 2/3\n",
      "820/820 - 39s - loss: 0.0440 - accuracy: 0.8827 - val_loss: 0.0438 - val_accuracy: 0.8814\n",
      "Epoch 3/3\n",
      "820/820 - 39s - loss: 0.0396 - accuracy: 0.8827 - val_loss: 0.0386 - val_accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Training the CNN\n",
    "\n",
    "# Compiling the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'hinge', metrics = ['accuracy'])\n",
    "\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "r=cnn.fit(x = train_generator, validation_data = validation_generator, epochs = 3, verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "843c54cf6e64417a56ba2fc126d45a866f69900720caa8efbfa97427d21e3981"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
